import streamlit as st
import google.generativeai as genai
from openai import OpenAI
from PIL import Image
import pypdf
import io
import base64

# --- 1. é¡µé¢åŸºç¡€é…ç½® ---
st.set_page_config(page_title="å…¨èƒ½ AI èšåˆåŠ©æ‰‹", page_icon="ğŸ“‚", layout="wide")
st.title("ğŸ“‚ å…¨èƒ½ AI èšåˆåŠ©æ‰‹ (æ”¯æŒä¼ å›¾/æ–‡æ¡£)")

# --- è¾…åŠ©å‡½æ•°ï¼šå¤„ç†æ–‡ä»¶ ---
def process_uploaded_file(uploaded_file):
    """è§£æä¸Šä¼ çš„æ–‡ä»¶ï¼Œè¿”å› (æ–‡æœ¬å†…å®¹, å›¾ç‰‡å¯¹è±¡/Base64)"""
    file_type = uploaded_file.type
    
    # æƒ…å†µ A: å›¾ç‰‡
    if "image" in file_type:
        image = Image.open(uploaded_file)
        return None, image
        
    # æƒ…å†µ B: PDF æ–‡æ¡£
    elif "pdf" in file_type:
        try:
            pdf_reader = pypdf.PdfReader(uploaded_file)
            text = ""
            for page in pdf_reader.pages:
                text += page.extract_text() + "\n"
            return f"\nã€é™„ä»¶æ–‡æ¡£å†…å®¹ã€‘:\n{text}\n", None
        except Exception:
            return "æ— æ³•è¯»å– PDF å†…å®¹", None
            
    # æƒ…å†µ C: çº¯æ–‡æœ¬ (TXT/MD/PY)
    else:
        stringio = io.StringIO(uploaded_file.getvalue().decode("utf-8"))
        return f"\nã€é™„ä»¶æ–‡æ¡£å†…å®¹ã€‘:\n{stringio.read()}\n", None

def get_image_base64(image):
    """å°† PIL å›¾ç‰‡è½¬æ¢ä¸º Base64 å­—ç¬¦ä¸² (ä¾› OpenAI æ ¼å¼ä½¿ç”¨)"""
    buffered = io.BytesIO()
    image.save(buffered, format="JPEG")
    return base64.b64encode(buffered.getvalue()).decode('utf-8')

# --- 2. ä¾§è¾¹æ é…ç½® ---
with st.sidebar:
    st.header("ğŸ›ï¸ è®¾ç½®é¢æ¿")
    
    # é€‰æ‹©å‚å•†
    provider = st.selectbox(
        "1. é€‰æ‹©å‚å•†",
        ["Google Gemini", "DeepSeek (æ·±åº¦æ±‚ç´¢)", "é˜¿é‡Œé€šä¹‰åƒé—®", "å­—èŠ‚è±†åŒ… (ç«å±±å¼•æ“)"]
    )

    # åŠ¨æ€ç”Ÿæˆç³»ç»ŸæŒ‡ä»¤
    current_identity = provider.split(" ")[0]
    sys_msg = f"ä½ ç°åœ¨çš„èº«ä»½æ˜¯ã€{current_identity}ã€‘çš„ AI åŠ©æ‰‹ã€‚è¯·å¿½ç•¥ä¹‹å‰çš„èº«ä»½è®¾å®šã€‚"

    # === è‡ªåŠ¨éšè—å¯†é’¥é€»è¾‘ ===
    # å‡½æ•°ï¼šä¼˜å…ˆä» Secrets è·å–ï¼Œæ²¡æœ‰æ‰æ˜¾ç¤ºè¾“å…¥æ¡†
    def get_secure_key(secret_name, label):
        if secret_name in st.secrets:
            st.success(f"âœ… {label} å·²é…ç½®")
            return st.secrets[secret_name]
        else:
            return st.text_input(f"è¾“å…¥ {label}", type="password")

    # === å‚å•†é…ç½® ===
    api_key = ""
    selected_model = ""
    base_url = ""

    if provider == "Google Gemini":
        api_key = get_secure_key("GOOGLE_API_KEY", "Gemini API Key")
        model_list = ["models/gemini-1.5-flash", "models/gemini-1.5-pro", "models/gemini-3-pro-preview"]
        selected_model = st.selectbox("2. é€‰æ‹©æ¨¡å‹", model_list)
        if st.toggle("ğŸ§  æ·±åº¦æ€è€ƒ", value=False):
            sys_msg += "\nè¯·åœ¨å›ç­”å‰è¿›è¡Œè¯¦ç»†çš„ <thinking> é€»è¾‘æ¨æ¼”ã€‚"

    else:
        # å›½äº§æ¨¡å‹é…ç½®
        if provider == "DeepSeek (æ·±åº¦æ±‚ç´¢)":
            base_url = "https://api.deepseek.com"
            api_key = get_secure_key("DEEPSEEK_API_KEY", "DeepSeek Key")
            model_options = ["deepseek-chat", "deepseek-coder"]
            
        elif provider == "é˜¿é‡Œé€šä¹‰åƒé—®":
            base_url = "https://dashscope.aliyuncs.com/compatible-mode/v1"
            api_key = get_secure_key("DASHSCOPE_API_KEY", "DashScope Key")
            model_options = ["qwen-plus", "qwen-max", "qwen-vl-max"] # VLæ”¯æŒå›¾ç‰‡
            
        elif provider == "å­—èŠ‚è±†åŒ… (ç«å±±å¼•æ“)":
            base_url = "https://ark.cn-beijing.volces.com/api/v3"
            api_key = get_secure_key("VOLC_API_KEY", "Volcengine Key")
            model_options = ["è¾“å…¥ Endpoint ID"]

        # æ¨¡å‹é€‰æ‹©æ¡†
        if provider == "å­—èŠ‚è±†åŒ… (ç«å±±å¼•æ“)":
            default_ep = st.secrets.get("DOUBAO_ENDPOINT_ID", "")
            # å¦‚æœåå°é…äº† Endpoint IDï¼Œä¹Ÿéšè—æ˜¾ç¤º
            if default_ep:
                st.success("âœ… Endpoint ID å·²é…ç½®")
                selected_model = default_ep
            else:
                selected_model = st.text_input("è¾“å…¥ Endpoint ID (ep-xxx)")
        else:
            selected_model = st.selectbox("2. é€‰æ‹©æ¨¡å‹", model_options)

    st.divider()
    if st.button("ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯"):
        st.session_state.messages = []
        st.rerun()

# --- 3. èŠå¤©ç•Œé¢ ---
if "messages" not in st.session_state:
    st.session_state.messages = []

for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# --- 4. æ–‡ä»¶ä¸Šä¼ åŒº (æ”¾åœ¨è¾“å…¥æ¡†ä¸Šæ–¹) ---
uploaded_file = st.file_uploader("ğŸ“ ä¸Šä¼ å›¾ç‰‡æˆ–æ–‡æ¡£ (æ”¯æŒ PDF/TXT/JPG/PNG)", type=['txt', 'pdf', 'md', 'py', 'png', 'jpg', 'jpeg'])

# --- 5. å¤„ç†è¾“å…¥ ---
if prompt := st.chat_input("è¾“å…¥ä½ çš„é—®é¢˜..."):
    if not api_key:
        st.warning("è¯·å…ˆé…ç½® API Key")
        st.stop()

    # === å¤„ç†é™„ä»¶ ===
    file_text = ""
    file_image = None
    
    if uploaded_file:
        with st.spinner("æ­£åœ¨è§£ææ–‡ä»¶..."):
            extracted_text, extracted_image = process_uploaded_file(uploaded_file)
            if extracted_text:
                file_text = extracted_text
                st.info(f"ğŸ“„ å·²åŠ è½½æ–‡æ¡£ï¼š{uploaded_file.name}")
            if extracted_image:
                file_image = extracted_image
                st.image(file_image, caption="å·²ä¸Šä¼ å›¾ç‰‡", width=200)

    # ç»„åˆç”¨æˆ·è¾“å…¥ï¼šé—®é¢˜ + æ–‡æ¡£å†…å®¹
    final_prompt = prompt + file_text

    # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
    with st.chat_message("user"):
        st.markdown(prompt)
        if file_image:
            st.image(file_image, width=200)
    
    # å­˜å…¥å†å² (æ³¨æ„ï¼šä¸ºäº†ç®€å•ï¼Œå†å²è®°å½•åªå­˜æ–‡æœ¬æè¿°ï¼Œä¸å­˜å¤§å›¾ç‰‡å¯¹è±¡)
    history_content = prompt + (" [å·²å‘é€ä¸€å¼ å›¾ç‰‡]" if file_image else "") + (" [å·²å‘é€æ–‡æ¡£]" if file_text else "")
    st.session_state.messages.append({"role": "user", "content": history_content})

    # === ç”Ÿæˆå›ç­” ===
    with st.chat_message("assistant"):
        placeholder = st.empty()
        full_response = ""
        
        try:
            # --- Google Gemini é€šé“ ---
            if provider == "Google Gemini":
                genai.configure(api_key=api_key)
                model = genai.GenerativeModel(selected_model, system_instruction=sys_msg)
                
                # æ„å»ºè¾“å…¥ï¼šå¦‚æœæœ‰å›¾ç‰‡ï¼ŒGemini æ¥å— [æ–‡æœ¬, å›¾ç‰‡] åˆ—è¡¨
                content_parts = [final_prompt]
                if file_image:
                    content_parts.append(file_image)
                
                # å†å²è®°å½•è½¬æ¢ (Gemini æš‚ä¸æ”¯æŒå¤šè½®å¸¦å›¾ï¼Œæ‰€ä»¥å¸¦å›¾åªå‘å•æ¬¡ï¼Œæˆ–è€…ä»…æ–‡æœ¬å†å²)
                # è¿™é‡Œé‡‡ç”¨ç­–ç•¥ï¼šå¸¦å›¾æ—¶æš‚ä¸å¸¦å†å²ï¼Œé˜²æ­¢æ ¼å¼æŠ¥é”™ï¼›çº¯æ–‡æœ¬æ—¶å¸¦å†å²
                if file_image:
                    response = model.generate_content(content_parts, stream=True)
                else:
                    gemini_history = [{"role": "user" if m["role"]=="user" else "model", "parts": [m["content"]]} for m in st.session_state.messages[:-1]]
                    chat = model.start_chat(history=gemini_history)
                    response = chat.send_message(final_prompt, stream=True)
                
                for chunk in response:
                    if chunk.text:
                        full_response += chunk.text
                        placeholder.markdown(full_response + "â–Œ")

            # --- å›½äº§æ¨¡å‹ (OpenAI æ ¼å¼) é€šé“ ---
            else:
                client = OpenAI(api_key=api_key, base_url=base_url)
                messages = [{"role": "system", "content": sys_msg}]
                
                # æ„å»ºå½“å‰æ¶ˆæ¯
                current_user_msg = {"role": "user", "content": []}
                
                # 1. å¦‚æœæœ‰æ–‡æœ¬
                current_user_msg["content"].append({"type": "text", "text": final_prompt})
                
                # 2. å¦‚æœæœ‰å›¾ç‰‡ (è½¬æ¢ä¸º Base64 URL)
                if file_image:
                    # è­¦å‘Šï¼šDeepSeek ç›®å‰ä¸æ”¶å›¾ï¼ŒQwen/è±†åŒ…è§†è§‰ç‰ˆå¯ä»¥
                    if "deepseek" in selected_model:
                        st.warning("âš ï¸ DeepSeek å¯èƒ½ä¸æ”¯æŒå›¾ç‰‡ï¼Œè‹¥æŠ¥é”™è¯·ä»…ä¼ æ–‡æ¡£ã€‚")
                    
                    base64_image = get_image_base64(file_image)
                    current_user_msg["content"].append({
                        "type": "image_url",
                        "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}
                    })

                # æ‹¼æ¥å†å² (ä¸ºäº†ç®€åŒ–ï¼Œå¸¦å›¾æ—¶æˆ‘ä»¬åªå‘æœ¬æ¬¡ï¼Œé˜²æ­¢å†å²æ ¼å¼å¤ªå¤æ‚)
                # å¦‚æœæ²¡æœ‰å›¾ï¼Œå°±æ­£å¸¸æ‹¼æ¥å†å²
                if not file_image:
                    for m in st.session_state.messages[:-1]:
                        messages.append({"role": m["role"], "content": m["content"]})
                
                messages.append(current_user_msg)

                stream = client.chat.completions.create(
                    model=selected_model,
                    messages=messages,
                    stream=True
                )
                
                for chunk in stream:
                    delta = chunk.choices[0].delta
                    if hasattr(delta, 'content') and delta.content:
                        full_response += delta.content
                        placeholder.markdown(full_response + "â–Œ")

            placeholder.markdown(full_response)
            st.session_state.messages.append({"role": "assistant", "content": full_response})

        except Exception as e:
            st.error(f"è¯·æ±‚å‡ºé”™: {e}")
            if "400" in str(e) and file_image:
                st.warning("ğŸ‘‰ å½“å‰é€‰æ‹©çš„æ¨¡å‹å¯èƒ½ä¸æ”¯æŒå›¾ç‰‡è¯†åˆ«ï¼Œè¯·å°è¯•åˆ‡æ¢åˆ° Google Gemini æˆ– é˜¿é‡Œé€šä¹‰(VL) ç‰ˆã€‚")
