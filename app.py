import streamlit as st
import google.generativeai as genai

# --- 1. é¡µé¢é…ç½® ---
st.set_page_config(page_title="æˆ‘çš„ AI åŠ©æ‰‹", page_icon="âœ¨", layout="wide")

# --- 2. ä¾§è¾¹æ ï¼šæ¨¡å¼åˆ‡æ¢ (ç±»ä¼¼å®˜æ–¹ Gemini) ---
with st.sidebar:
    st.header("âœ¨ æ¨¡å‹è®¾ç½®")
    
    # åˆ›å»ºä¸€ä¸ªäºŒé€‰ä¸€çš„å•é€‰æŒ‰é’®
    mode = st.radio(
        "é€‰æ‹©æ¨¡å¼ï¼š",
        ["ğŸš€ æé€Ÿå“åº” (Flash)", "ğŸ§  æ·±åº¦æ€è€ƒ (Pro)"],
        captions=["é€Ÿåº¦æœ€å¿«ï¼Œé€‚åˆæ—¥å¸¸é—®ç­”", "é€»è¾‘æ›´å¼ºï¼Œä¼šè‡ªåŠ¨è¿›è¡Œæ·±åº¦æ¨ç†"]
    )

    st.divider()
    
    # æ¸…ç©ºæŒ‰é’®
    if st.button("ğŸ—‘ï¸ å¼€å¯æ–°å¯¹è¯", use_container_width=True):
        st.session_state.messages = []
        st.rerun()

# --- 3. æ ¸å¿ƒé€»è¾‘é…ç½® ---
try:
    api_key = st.secrets["GOOGLE_API_KEY"]
    genai.configure(api_key=api_key)

    # æ ¹æ®é€‰æ‹©çš„æ¨¡å¼ï¼Œè‡ªåŠ¨åˆ†é… æ¨¡å‹ å’Œ æŒ‡ä»¤
    if mode == "ğŸš€ æé€Ÿå“åº” (Flash)":
        # è¿™é‡Œç”¨ Flash æ¨¡å‹ï¼Œè¿½æ±‚é€Ÿåº¦
        # å¦‚æœä½ çš„è´¦å·ä¸æ”¯æŒ flashï¼Œå¯ä»¥æ”¹å› 'models/gemini-3-pro-preview'
        target_model = "models/gemini-1.5-flash" 
        sys_instruction = "ä½ æ˜¯ä¸€ä¸ªç®€æ´é«˜æ•ˆçš„åŠ©æ‰‹ã€‚å›ç­”è¦å¿«ï¼Œç›´æ¥åˆ‡å…¥é‡ç‚¹ã€‚"
        
    else: # æ·±åº¦æ€è€ƒæ¨¡å¼
        # è¿™é‡Œç”¨ä½ ä¹‹å‰æµ‹é€šçš„é‚£ä¸ªé«˜çº§æ¨¡å‹
        target_model = "models/gemini-3-pro-preview"
        # æ³¨å…¥â€œæ€ç»´é“¾â€æŒ‡ä»¤ï¼Œè®©å®ƒæ¨¡ä»¿ o1 æ¨¡å‹è¿›è¡Œæ€è€ƒ
        sys_instruction = """
        ä½ æ˜¯ä¸€ä¸ªæ·±åº¦æ€è€ƒä¸“å®¶ã€‚
        åœ¨å›ç­”ç”¨æˆ·ä¹‹å‰ï¼Œä½ å¿…é¡»å…ˆåœ¨ä¸€ä¸ª <thinking> æ ‡ç­¾å—ä¸­è¿›è¡Œè¯¦ç»†çš„é€»è¾‘æ¨æ¼”ã€æ­¥éª¤è§„åˆ’å’Œè‡ªæˆ‘çº é”™ã€‚
        æ€è€ƒè¿‡ç¨‹è¦å…¨é¢ï¼Œç„¶åå†ç»™å‡ºæœ€ç»ˆçš„å›ç­”ã€‚
        """

    # åˆå§‹åŒ–æ¨¡å‹
    model = genai.GenerativeModel(
        target_model,
        system_instruction=sys_instruction
    )

except Exception as e:
    # å¦‚æœæ¨¡å‹åå­—ä¸å¯¹ï¼Œè¿™é‡Œä¼šæç¤º
    st.error(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
    st.info("æç¤ºï¼šå¦‚æœ Flash æŠ¥é”™ 404ï¼Œè¯·å»ä»£ç é‡ŒæŠŠ 'gemini-1.5-flash' æ”¹æˆä½ èƒ½ç”¨çš„æ¨¡å‹åã€‚")
    st.stop()

# --- 4. èŠå¤©ç•Œé¢ ---
st.title("âœ¨ Gemini AI åŠ©æ‰‹")

# åˆå§‹åŒ–å†å²
if "messages" not in st.session_state:
    st.session_state.messages = []

# æ˜¾ç¤ºå†å²
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# å¤„ç†è¾“å…¥
if prompt := st.chat_input("æƒ³é—®ç‚¹ä»€ä¹ˆï¼Ÿ"):
    # 1. æ˜¾ç¤ºç”¨æˆ·é—®é¢˜
    with st.chat_message("user"):
        st.markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    # 2. ç”Ÿæˆå›ç­”
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""
        
        try:
            # å¼€å¯æµå¼ä¼ è¾“ (stream=True) ä¿è¯é€Ÿåº¦æ„Ÿ
            response_stream = model.generate_content(prompt, stream=True)
            
            for chunk in response_stream:
                if chunk.text:
                    full_response += chunk.text
                    message_placeholder.markdown(full_response + "â–Œ")
            
            message_placeholder.markdown(full_response)
            st.session_state.messages.append({"role": "assistant", "content": full_response})
            
        except Exception as e:
            st.error(f"ç”Ÿæˆå‡ºé”™: {e}")
            if "404" in str(e) and "flash" in target_model:
                st.warning("ä½ çš„è´¦å·å¯èƒ½æš‚ä¸æ”¯æŒ Flash æ¨¡å‹ï¼Œè¯·åˆ‡æ¢åˆ° 'æ·±åº¦æ€è€ƒ' æ¨¡å¼ä½¿ç”¨ã€‚")
